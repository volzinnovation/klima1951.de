name: Daily Data Processing

on:
  schedule:
    - cron: '0 10 * * *' # Executes at 12:00 (noon) German time (UTC+2 in summer, UTC+1 in winter)
  workflow_dispatch: # Allows manual triggering

jobs:
  run-etl-scripts:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
          
      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt

      - name: Create data directories
        run: |
          mkdir -p data/hyras
          cd data/hyras
          # Step 1: Download data for the current year
          python ../../etl/download_data.py --year current



      - name: Run ETL Pipeline for Current Year
        run: |
          # Step 2: Create daily JSON files from the downloaded data
          python ../etl/create_daily_json.py --years current --overwrite

          # Step 3: Merge the individual JSON files into all.json for the current year
          python ../etl/merge_yearly_json.py --years current

          # Step 4: Re-aggregate all years of data for each place, including the new data
          python ../etl/merge_place_data.py --overwrite

          # Step 5: Recalculate all statistics
          python ../etl/create_stats.py --years all --overwrite
        working-directory: data

      - name: Commit and push changes
        env:
          PAT_TOKEN: ${{ secrets.DAILY_PAT }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git commit -m "Daily data update" || echo "No changes to commit"
          git push https://x-access-token:${PAT_TOKEN}@github.com/${{ github.repository }}.git HEAD:${{ github.ref_name }}
